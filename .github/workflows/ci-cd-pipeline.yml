# User Whisperer Platform - Comprehensive CI/CD Pipeline
# Multi-stage pipeline with quality gates, security scanning, and blue-green deployment

name: User Whisperer CI/CD Pipeline

on:
  push:
    branches: [main, develop, release/*]
  pull_request:
    branches: [main, develop]
  release:
    types: [created, published]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      force_deploy:
        description: 'Force deployment without approval'
        required: false
        default: false
        type: boolean

env:
  # Container Registry
  REGISTRY: gcr.io
  PROJECT_ID: userwhisperer-prod
  
  # Kubernetes
  CLUSTER_NAME: userwhisperer-cluster
  CLUSTER_ZONE: us-central1-a
  
  # Application
  APP_NAME: userwhisperer
  APP_VERSION: ${{ github.sha }}
  
  # Quality Gates
  MIN_COVERAGE: 90
  MAX_VULNERABILITIES: 0
  MAX_DUPLICATED_LINES: 3

# Global job defaults
defaults:
  run:
    shell: bash

jobs:
  # ==========================================
  # STAGE 1: CODE QUALITY & SECURITY
  # ==========================================
  
  quality-gate:
    name: üîç Quality Gate
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    outputs:
      should-deploy: ${{ steps.quality-check.outputs.should-deploy }}
      version: ${{ steps.version.outputs.version }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for SonarCloud
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        echo "üì¶ Installing Node.js dependencies..."
        npm ci --prefer-offline
        
        echo "üì¶ Installing Python dependencies..."
        pip install -r requirements.txt
        pip install flake8 black mypy safety bandit semgrep
    
    - name: Generate version
      id: version
      run: |
        if [[ "${{ github.event_name }}" == "release" ]]; then
          VERSION="${{ github.event.release.tag_name }}"
        else
          VERSION="${{ github.sha }}"
        fi
        echo "version=${VERSION}" >> $GITHUB_OUTPUT
        echo "üè∑Ô∏è Version: ${VERSION}"
    
    # Code Quality Checks
    - name: Lint JavaScript/TypeScript
      run: |
        echo "üîç Running ESLint..."
        npm run lint -- --format=json --output-file=eslint-report.json || true
        
        echo "üîç Running TypeScript compiler..."
        npm run typecheck
    
    - name: Lint Python
      run: |
        echo "üîç Running flake8..."
        flake8 --format=json --output-file=flake8-report.json src/ || true
        
        echo "üîç Running black..."
        black --check --diff src/
        
        echo "üîç Running mypy..."
        mypy src/ --junit-xml=mypy-report.xml || true
    
    # Security Scanning
    - name: Security scan - Dependencies
      run: |
        echo "üîí Scanning npm dependencies..."
        npm audit --audit-level=moderate --json > npm-audit.json || true
        
        echo "üîí Scanning Python dependencies..."
        safety check --json --output safety-report.json || true
    
    - name: Security scan - Code
      run: |
        echo "üîí Running Bandit (Python)..."
        bandit -r src/ -f json -o bandit-report.json || true
        
        echo "üîí Running Semgrep..."
        semgrep --config=auto --json --output=semgrep-report.json src/ || true
    
    # License Compliance
    - name: License check
      run: |
        echo "‚öñÔ∏è Checking licenses..."
        npm install -g license-checker
        license-checker --onlyAllow 'MIT;Apache-2.0;BSD-3-Clause;BSD-2-Clause;ISC;0BSD' --json > license-report.json
    
    # Code Quality Analysis
    - name: SonarCloud Scan
      uses: SonarSource/sonarcloud-github-action@master
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
      with:
        args: >
          -Dsonar.projectKey=userwhisperer_platform
          -Dsonar.organization=userwhisperer
          -Dsonar.javascript.lcov.reportPaths=coverage/lcov.info
          -Dsonar.python.coverage.reportPaths=coverage.xml
          -Dsonar.eslint.reportPaths=eslint-report.json
          -Dsonar.python.flake8.reportPaths=flake8-report.json
    
    # Quality Gate Decision
    - name: Quality gate decision
      id: quality-check
      run: |
        echo "üìä Analyzing quality metrics..."
        
        # Initialize variables
        SHOULD_DEPLOY="true"
        ISSUES=""
        
        # Check test coverage
        if [[ -f coverage/coverage-summary.json ]]; then
          COVERAGE=$(jq -r '.total.lines.pct' coverage/coverage-summary.json)
          if (( $(echo "$COVERAGE < $MIN_COVERAGE" | bc -l) )); then
            SHOULD_DEPLOY="false"
            ISSUES="$ISSUES\n‚ùå Coverage ($COVERAGE%) below minimum ($MIN_COVERAGE%)"
          else
            echo "‚úÖ Coverage: $COVERAGE%"
          fi
        fi
        
        # Check security vulnerabilities
        if [[ -f npm-audit.json ]]; then
          HIGH_VULNS=$(jq '.metadata.vulnerabilities.high // 0' npm-audit.json)
          CRITICAL_VULNS=$(jq '.metadata.vulnerabilities.critical // 0' npm-audit.json)
          TOTAL_VULNS=$((HIGH_VULNS + CRITICAL_VULNS))
          
          if [[ $TOTAL_VULNS -gt $MAX_VULNERABILITIES ]]; then
            SHOULD_DEPLOY="false"
            ISSUES="$ISSUES\n‚ùå Security vulnerabilities found: $TOTAL_VULNS"
          else
            echo "‚úÖ No critical security vulnerabilities"
          fi
        fi
        
        # Set output
        echo "should-deploy=$SHOULD_DEPLOY" >> $GITHUB_OUTPUT
        
        if [[ "$SHOULD_DEPLOY" == "false" ]]; then
          echo -e "üö´ Quality gate failed:$ISSUES"
          exit 1
        else
          echo "‚úÖ Quality gate passed"
        fi
    
    # Upload artifacts
    - name: Upload quality reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: quality-reports
        path: |
          *-report.json
          *-report.xml
          coverage/
        retention-days: 30
  
  # ==========================================
  # STAGE 2: TESTING
  # ==========================================
  
  unit-tests:
    name: üß™ Unit Tests
    runs-on: ubuntu-latest
    needs: quality-gate
    timeout-minutes: 30
    
    strategy:
      fail-fast: false
      matrix:
        service: 
          - event-ingestion
          - behavioral-analysis
          - decision-engine
          - content-generation
          - channel-orchestration
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup test environment
      run: |
        echo "üèóÔ∏è Setting up test environment for ${{ matrix.service }}..."
        
        # Start test dependencies
        docker-compose -f docker-compose.test.yml up -d postgres redis
        sleep 10
        
        # Wait for services to be ready
        ./scripts/wait-for-services.sh
    
    - name: Setup Node.js
      if: contains(fromJson('["event-ingestion", "api-gateway"]'), matrix.service)
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: services/${{ matrix.service }}/package-lock.json
    
    - name: Setup Python
      if: contains(fromJson('["behavioral-analysis", "decision-engine", "content-generation"]'), matrix.service)
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: services/${{ matrix.service }}/requirements.txt
    
    - name: Setup Go
      if: matrix.service == 'channel-orchestration'
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'
        cache-dependency-path: services/${{ matrix.service }}/go.sum
    
    - name: Install dependencies
      run: |
        cd services/${{ matrix.service }}
        
        if [[ -f package.json ]]; then
          npm ci
        elif [[ -f requirements.txt ]]; then
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio
        elif [[ -f go.mod ]]; then
          go mod download
        fi
    
    - name: Run unit tests
      run: |
        cd services/${{ matrix.service }}
        
        echo "üß™ Running unit tests for ${{ matrix.service }}..."
        
        if [[ -f package.json ]]; then
          npm test -- --coverage --maxWorkers=2
        elif [[ -f requirements.txt ]]; then
          python -m pytest tests/unit/ --cov=src --cov-report=xml --cov-report=html --junitxml=junit.xml -v
        elif [[ -f go.mod ]]; then
          go test -v -race -coverprofile=coverage.out -covermode=atomic ./...
        fi
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.service }}
        path: |
          services/${{ matrix.service }}/coverage/
          services/${{ matrix.service }}/junit.xml
          services/${{ matrix.service }}/coverage.out
        retention-days: 30
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: services/${{ matrix.service }}/coverage.xml
        flags: ${{ matrix.service }}
        name: ${{ matrix.service }}-coverage
        fail_ci_if_error: false

  integration-tests:
    name: üîó Integration Tests
    runs-on: ubuntu-latest
    needs: quality-gate
    timeout-minutes: 45
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: userwhisperer_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        npm ci
        pip install -r requirements.txt
        pip install pytest pytest-asyncio aiohttp
    
    - name: Run integration tests
      env:
        POSTGRES_URL: postgresql://test:test@localhost:5432/userwhisperer_test
        REDIS_URL: redis://localhost:6379
        TEST_ENVIRONMENT: true
      run: |
        echo "üîó Running integration tests..."
        python -m pytest tests/integration/ -v --junitxml=integration-results.xml
    
    - name: Upload integration test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: integration-results.xml
        retention-days: 30

  e2e-tests:
    name: üé≠ End-to-End Tests
    runs-on: ubuntu-latest
    needs: [quality-gate, unit-tests]
    timeout-minutes: 60
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup test environment
      run: |
        echo "üèóÔ∏è Setting up full test environment..."
        docker-compose -f docker-compose.test.yml up -d
        
        # Wait for all services to be ready
        ./scripts/wait-for-services.sh --timeout=300
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install test dependencies
      run: |
        pip install -r requirements-test.txt
    
    - name: Run E2E tests
      run: |
        echo "üé≠ Running end-to-end tests..."
        python -m pytest tests/e2e/ -v --junitxml=e2e-results.xml --html=e2e-report.html
    
    - name: Upload E2E test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: e2e-test-results
        path: |
          e2e-results.xml
          e2e-report.html
        retention-days: 30
    
    - name: Cleanup test environment
      if: always()
      run: |
        docker-compose -f docker-compose.test.yml down -v

  # ==========================================
  # STAGE 3: BUILD & PUBLISH
  # ==========================================
  
  build-images:
    name: üèóÔ∏è Build Images
    runs-on: ubuntu-latest
    needs: [quality-gate, unit-tests, integration-tests]
    if: github.event_name == 'push' || github.event_name == 'release' || github.event_name == 'workflow_dispatch'
    timeout-minutes: 60
    
    strategy:
      fail-fast: false
      matrix:
        service:
          - event-ingestion
          - behavioral-analysis
          - decision-engine
          - content-generation
          - channel-orchestration
          - api-gateway
    
    outputs:
      image-tags: ${{ steps.build.outputs.image-tags }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      with:
        driver-opts: |
          image=moby/buildkit:v0.12.0
    
    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_CREDENTIALS }}
    
    - name: Configure Docker for GCR
      run: |
        gcloud auth configure-docker gcr.io
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
    
    - name: Build and push Docker image
      id: build
      uses: docker/build-push-action@v5
      with:
        context: ./services/${{ matrix.service }}
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          VERSION=${{ needs.quality-gate.outputs.version }}
          BUILD_DATE=${{ github.event.head_commit.timestamp }}
          VCS_REF=${{ github.sha }}
          SERVICE_NAME=${{ matrix.service }}
    
    - name: Generate SBOM
      uses: anchore/sbom-action@v0
      with:
        image: ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/${{ matrix.service }}:${{ github.sha }}
        format: spdx-json
        output-file: ${{ matrix.service }}-sbom.spdx.json
    
    - name: Scan image for vulnerabilities
      uses: anchore/scan-action@v3
      id: scan
      with:
        image: ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/${{ matrix.service }}:${{ github.sha }}
        fail-build: false
        severity-cutoff: high
    
    - name: Upload vulnerability report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: vulnerability-report-${{ matrix.service }}
        path: |
          ${{ steps.scan.outputs.sarif }}
          ${{ matrix.service }}-sbom.spdx.json
        retention-days: 30

  # ==========================================
  # STAGE 4: DEPLOYMENT
  # ==========================================
  
  deploy-staging:
    name: üöÄ Deploy to Staging
    runs-on: ubuntu-latest
    needs: [quality-gate, e2e-tests, build-images]
    if: |
      (github.ref == 'refs/heads/develop' || 
       github.event_name == 'workflow_dispatch') &&
      needs.quality-gate.outputs.should-deploy == 'true'
    environment: 
      name: staging
      url: https://staging.userwhisperer.ai
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_CREDENTIALS }}
    
    - name: Get GKE credentials
      uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ env.CLUSTER_NAME }}-staging
        location: ${{ env.CLUSTER_ZONE }}
    
    - name: Deploy to Kubernetes
      run: |
        echo "üöÄ Deploying to staging environment..."
        
        # Update deployment images
        SERVICES="event-ingestion behavioral-analysis decision-engine content-generation channel-orchestration api-gateway"
        
        for SERVICE in $SERVICES; do
          echo "üì¶ Updating $SERVICE to ${{ github.sha }}"
          kubectl set image deployment/${SERVICE} \
            ${SERVICE}=${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/${SERVICE}:${{ github.sha }} \
            -n userwhisperer-staging
        done
        
        # Wait for deployments to complete
        for SERVICE in $SERVICES; do
          echo "‚è≥ Waiting for $SERVICE deployment..."
          kubectl rollout status deployment/${SERVICE} \
            -n userwhisperer-staging \
            --timeout=300s
        done
    
    - name: Run smoke tests
      run: |
        echo "üß™ Running staging smoke tests..."
        
        # Wait for services to be fully ready
        sleep 30
        
        # Run smoke tests
        python -m pytest tests/smoke/ \
          --base-url=https://staging.userwhisperer.ai \
          -v --junitxml=smoke-results.xml
    
    - name: Upload smoke test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: smoke-test-results-staging
        path: smoke-results.xml
        retention-days: 30
    
    - name: Notify deployment status
      uses: 8398a7/action-slack@v3
      if: always()
      with:
        status: ${{ job.status }}
        text: |
          üöÄ Staging deployment ${{ job.status }}
          ‚Ä¢ Version: ${{ needs.quality-gate.outputs.version }}
          ‚Ä¢ Commit: ${{ github.sha }}
          ‚Ä¢ Branch: ${{ github.ref_name }}
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}

  deploy-production:
    name: üåü Deploy to Production
    runs-on: ubuntu-latest
    needs: [quality-gate, deploy-staging, build-images]
    if: |
      (github.ref == 'refs/heads/main' || 
       github.event_name == 'release' ||
       (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'production')) &&
      needs.quality-gate.outputs.should-deploy == 'true'
    environment: 
      name: production
      url: https://api.userwhisperer.ai
    timeout-minutes: 45
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_CREDENTIALS }}
    
    - name: Get GKE credentials
      uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ env.CLUSTER_NAME }}
        location: ${{ env.CLUSTER_ZONE }}
    
    - name: Pre-deployment backup
      run: |
        echo "üíæ Creating pre-deployment backup..."
        ./scripts/backup-production.sh
    
    - name: Blue-Green Deployment
      run: |
        echo "üîÑ Starting blue-green deployment to production..."
        
        # Run the comprehensive deployment script
        ./scripts/deploy-production.sh \
          --version="${{ needs.quality-gate.outputs.version }}" \
          --image-tag="${{ github.sha }}" \
          --registry="${{ env.REGISTRY }}/${{ env.PROJECT_ID }}" \
          --namespace="userwhisperer-prod" \
          --strategy="blue-green" \
          --timeout=600
    
    - name: Run production health checks
      run: |
        echo "üè• Running production health checks..."
        
        # Comprehensive health check script
        ./scripts/health-check-production.sh \
          --timeout=300 \
          --check-all-services
    
    - name: Run production smoke tests
      run: |
        echo "üß™ Running production smoke tests..."
        
        python -m pytest tests/smoke/ \
          --base-url=https://api.userwhisperer.ai \
          --production-mode \
          -v --junitxml=smoke-results-prod.xml
    
    - name: Upload production test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: smoke-test-results-production
        path: smoke-results-prod.xml
        retention-days: 90
    
    - name: Create GitHub release
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: v${{ needs.quality-gate.outputs.version }}
        release_name: Release v${{ needs.quality-gate.outputs.version }}
        body: |
          üöÄ **Production Release v${{ needs.quality-gate.outputs.version }}**
          
          **Changes in this release:**
          ${{ github.event.head_commit.message }}
          
          **Deployment Info:**
          - Commit: ${{ github.sha }}
          - Deployed: ${{ github.event.head_commit.timestamp }}
          - Environment: Production
          
          **Quality Metrics:**
          - All tests passed ‚úÖ
          - Security scan passed ‚úÖ
          - Quality gate passed ‚úÖ
        draft: false
        prerelease: false
    
    - name: Notify successful deployment
      uses: 8398a7/action-slack@v3
      if: success()
      with:
        status: success
        text: |
          üéâ **PRODUCTION DEPLOYMENT SUCCESSFUL** üéâ
          
          ‚Ä¢ Version: ${{ needs.quality-gate.outputs.version }}
          ‚Ä¢ Commit: ${{ github.sha }}
          ‚Ä¢ Deployed by: ${{ github.actor }}
          ‚Ä¢ All health checks passed ‚úÖ
          
          üîó Production: https://api.userwhisperer.ai
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
    
    - name: Notify failed deployment
      uses: 8398a7/action-slack@v3
      if: failure()
      with:
        status: failure
        text: |
          üö® **PRODUCTION DEPLOYMENT FAILED** üö®
          
          ‚Ä¢ Version: ${{ needs.quality-gate.outputs.version }}
          ‚Ä¢ Commit: ${{ github.sha }}
          ‚Ä¢ Failed step: ${{ job.status }}
          
          Please check the deployment logs and take action immediately.
        webhook_url: ${{ secrets.SLACK_WEBHOOK_ALERTS }}

  # ==========================================
  # STAGE 5: POST-DEPLOYMENT
  # ==========================================
  
  post-deployment:
    name: üìä Post-Deployment Validation
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: success()
    timeout-minutes: 20
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Wait for production stabilization
      run: |
        echo "‚è≥ Waiting for production to stabilize..."
        sleep 300  # 5 minutes
    
    - name: Run performance tests
      run: |
        echo "‚ö° Running performance tests against production..."
        
        # Install k6 for load testing
        curl -s https://github.com/grafana/k6/releases/download/v0.46.0/k6-v0.46.0-linux-amd64.tar.gz | tar xzf -
        sudo mv k6-v0.46.0-linux-amd64/k6 /usr/local/bin/
        
        # Run performance tests
        k6 run tests/performance/load-test.js \
          --env BASE_URL=https://api.userwhisperer.ai \
          --env API_KEY=${{ secrets.PROD_API_KEY }}
    
    - name: Validate metrics
      run: |
        echo "üìä Validating production metrics..."
        
        # Check key metrics via Prometheus API
        python scripts/validate-metrics.py \
          --prometheus-url=${{ secrets.PROMETHEUS_URL }} \
          --duration=5m \
          --check-sla
    
    - name: Update deployment tracking
      run: |
        echo "üìù Updating deployment tracking..."
        
        # Update deployment database
        python scripts/track-deployment.py \
          --version="${{ needs.quality-gate.outputs.version }}" \
          --environment="production" \
          --status="successful" \
          --commit="${{ github.sha }}"

# Security: Ensure secrets are properly managed
env-protection:
  runs-on: ubuntu-latest
  if: always()
  steps:
  - name: Validate secrets
    run: |
      echo "üîê Validating required secrets are present..."
      
      REQUIRED_SECRETS="GCP_CREDENTIALS SONAR_TOKEN SLACK_WEBHOOK PROMETHEUS_URL PROD_API_KEY"
      MISSING_SECRETS=""
      
      for secret in $REQUIRED_SECRETS; do
        if [[ -z "${!secret}" ]]; then
          MISSING_SECRETS="$MISSING_SECRETS $secret"
        fi
      done
      
      if [[ -n "$MISSING_SECRETS" ]]; then
        echo "‚ùå Missing required secrets:$MISSING_SECRETS"
        exit 1
      else
        echo "‚úÖ All required secrets are present"
      fi
